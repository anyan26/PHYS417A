{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to CNNs\n",
        "\n",
        "* it is difficult to achieve >95% accuracy with FCN\n",
        "* FCNs does not extract features well\n",
        "* too many parameters\n",
        "\n",
        "**Specialized Layers for Feature Extraction**\n",
        "* convoluted networks!\n",
        "\n",
        "**Convolutional Layers**\n",
        "\n",
        "Take input image and process through kernel to produce new convoluted feature\n",
        "\n",
        "how many step to take depend on stride"
      ],
      "metadata": {
        "id": "UXJdswn3isxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementation for convolutional layer\n",
        "\n",
        "torch.nn.Conv2d(in_channels = 2, out_channels = 3,\n",
        "                kernel_size = 4, stride = 2, padding = 1)\n",
        "#stride default = 1, padding default = 0\n"
      ],
      "metadata": {
        "id": "KZ9zQYcQjWgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pooling Layer**\n",
        "\n",
        "torch.nn.MaxPool2D(kernel_size = 2, stride = 2)\n",
        "\n",
        "torch.nn.AvgPool2D(kernel_size = 2, stride = 2)"
      ],
      "metadata": {
        "id": "uKz_Hd5vpMBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Application of CNNs\n",
        "\n",
        "* Image segmentation\n",
        "\n",
        "  given a image, separate the image into classes ex: (table and chair)\n",
        "\n",
        "  application: facial segmentation, autonomous driving, geo land sensing, etc.\n",
        "\n",
        "* Visual recognition task\n",
        "\n",
        "  assign a whole image into a class\n",
        "\n",
        "  medical diagnosis, AI controlled gaming, astronomical image analysis"
      ],
      "metadata": {
        "id": "tj4gWq8AsV5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Implementation in PyTorch"
      ],
      "metadata": {
        "id": "AiIwHgq7sbj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_features_flat = train_features.reshape((1000, 28*28))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features_flat).reshape(1000, 28, 28)\n",
        "\n",
        "#split into train, test, and validation\n",
        "train_features = np.reshape(train_features, (900, 1, 28, 28))\n",
        "#N, channels, H, W\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__():\n",
        "\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.cnn1 = torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride = 1, padding = 2)\n",
        "    self.maxpool1 = torch.nn.MaxPool2D(kernel_size = 2)\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(32*7*7, 10)\n",
        "\n",
        "  #image -> cnn1 -> ReLU -> maxpool1 -> cnn2 -> ReLU -> maxpool2\n",
        "  def forward(self, x):\n",
        "    conv1_out = torch.nn.functional.relu(self.cnn1(x))\n",
        "    pool1_out = self.maxpool1(conv1_out)\n",
        "\n",
        "    fin_input = pool1_out.view(pool1_out.size(0), -1) #flatten pool 1\n",
        "    output = self.fc1(fin_input)\n",
        "\n",
        "    return output\n",
        "\n",
        "  torch.manual_seed(25) #results will be reproducible\n",
        "\n",
        "  #using mini-batch\n",
        "\n",
        "  torch.batches_features = torch.split(train_inputs, batchsize)\n"
      ],
      "metadata": {
        "id": "F4xkg9kYv1By"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}